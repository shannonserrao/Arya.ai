{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shannonserrao/Arya.ai/blob/main/Vidhya_Census.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install deepchecks --User\n",
        "# !pip install deepchecks --upgrade\n",
        "# !pip install colorama\n",
        "# pip install matplotlib==3.1.3"
      ],
      "metadata": {
        "id": "5uqABB4ebDMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GfdGvNYAF3r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbqWiRpz-dlG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# import shap\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def custom_formatwarning(msg, *args, **kwargs):\n",
        "    # ignore everything except the message\n",
        "    return str(msg) + '\\n'\n",
        "warnings.formatwarning = custom_formatwarning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deepchecks.tabular.checks import CalibrationScore\n",
        "from deepchecks.tabular.checks import ConfusionMatrixReport\n",
        "from deepchecks.tabular.checks import ModelInfo\n",
        "# from deepchecks.tabular.checks import PerformanceReport\n",
        "from deepchecks.tabular.checks import RegressionErrorDistribution\n",
        "from deepchecks.tabular.checks import RegressionSystematicError\n",
        "from deepchecks.tabular.checks import RocReport\n",
        "from deepchecks.tabular.checks import SegmentPerformance\n",
        "from deepchecks.tabular.checks import SimpleModelComparison\n",
        "from deepchecks.tabular.checks import MultiModelPerformanceReport\n",
        "from deepchecks.tabular import Dataset\n",
        "\n",
        "bold= '\\033[1m'\n",
        "import colorama\n",
        "from colorama import Fore\n",
        "\n",
        "# import some classification models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "\n",
        "# import needed functions\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "7uNXjXJGdRNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kjvn11FEI5B4"
      },
      "source": [
        "## DATA Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPwnE6mV-jLK"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Aditya-Mankar/Census-Income-Prediction/master/adult.csv\")\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pre-processing"
      ],
      "metadata": {
        "id": "pk3igiUYfy2q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8DO6ADOUChE"
      },
      "outputs": [],
      "source": [
        "questioned_columns = ['workclass' ,'occupation' , 'native.country']\n",
        "\n",
        "for column in questioned_columns:\n",
        "        df[column] = df[column].replace({'?': 'Unknown'})\n",
        "\n",
        "# df.isin(['?']).sum()\n",
        "df1 = df.copy()\n",
        "# Scalling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "numerical = ['age', 'capital.gain', 'capital.loss', 'hours.per.week', 'fnlwgt']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df1[numerical] = scaler.fit_transform(df1[numerical])\n",
        "\n",
        "# Encoding\n",
        "df1['sex'] = df1.sex.replace({\"Female\": 0, \"Male\": 1})\n",
        "df1['income'] = df1.income.replace({\"<=50K\": 0, \">50K\": 1})\n",
        "\n",
        "# Create dummy variables\n",
        "df1 = pd.get_dummies(df1)\n",
        "\n",
        "encoded = list(df1.columns)\n",
        "print(\"{} total features after one-hot encoding.\".format(len(encoded)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2e1thyJQV7P"
      },
      "outputs": [],
      "source": [
        "# Partioning the data\n",
        "X = df1.drop('income', axis=1)\n",
        "y = df1['income']\n",
        "\n",
        "# Splitting to training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFx_FfXvV1q2"
      },
      "outputs": [],
      "source": [
        "# categorical_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsGzKksoQV4J"
      },
      "outputs": [],
      "source": [
        "models = {}\n",
        "\n",
        "# models with default parameter\n",
        "models['LogisticRegression'] = LogisticRegression()\n",
        "models['RandomForest'] = RandomForestClassifier()\n",
        "models['AdaBoost'] = AdaBoostClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Us0xomb9QV1G"
      },
      "outputs": [],
      "source": [
        "# Cross validation\n",
        "for model_name in models:\n",
        "    model = models[model_name]\n",
        "    print(model)\n",
        "    results = cross_validate(model, X, y, cv=5, scoring=['accuracy', 'f1'], return_train_score=True)\n",
        "    \n",
        "    print(model_name + \":\")\n",
        "    print(\"Accuracy:\" , 'train: ', results['train_accuracy'].mean(), '| test: ', results['test_accuracy'].mean())\n",
        "    print(\"F1-score:\" , 'train: ', results['train_f1'].mean(), '| test: ', results['test_f1'].mean())\n",
        "    print(\"---------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBfcKioJV1q2"
      },
      "outputs": [],
      "source": [
        "# from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
        "# from sklearn.metrics import accuracy_score, brier_score_loss, log_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAPyNnJHV1q2"
      },
      "outputs": [],
      "source": [
        "# # Create classifiers\n",
        "# lr = LogisticRegression()\n",
        "# # knn = KNeighborsClassifier()\n",
        "# # dtc = DecisionTreeClassifier(random_state=42)\n",
        "# rfc = RandomForestClassifier(random_state=42, verbose=0)\n",
        "\n",
        "# '''Plot calibration plots'''\n",
        "\n",
        "# plt.figure(figsize=(15, 10))\n",
        "# ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
        "# ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
        "\n",
        "# ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
        "\n",
        "# for clf, name in [(lr, 'Logistic'),(rfc, 'RandomForest')]:\n",
        "    \n",
        "#     clf.fit(X_train,y_train)\n",
        "#     prob_pos = clf.predict_proba(X_test)[:, 1]\n",
        "#     fraction_of_positives, mean_predicted_value = calibration_curve(y_test, prob_pos, n_bins=10)\n",
        "\n",
        "#     ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"%s\" % (name, ))\n",
        "#     ax2.hist(prob_pos, range=(0, 1), bins=10, label=name, histtype=\"step\", lw=2)\n",
        "    \n",
        "\n",
        "# ax1.set_ylabel(\"Fraction of positives\")\n",
        "# ax1.set_ylim([-0.05, 1.05])\n",
        "# ax1.legend(loc=\"lower right\")\n",
        "# ax1.set_title('Classifier Calibration plots  (reliability curve)', fontsize=20)\n",
        "\n",
        "# ax2.set_xlabel(\"Mean predicted value\")\n",
        "# ax2.set_ylabel(\"Count\")\n",
        "# ax2.legend(loc=\"upper center\", ncol=2)\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xlmy0QtbV1q2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKwScPfPV1q2"
      },
      "outputs": [],
      "source": [
        "# # Classifier\n",
        "# rfc = RandomForestClassifier(random_state=42, verbose=0)\n",
        "\n",
        "# # Train\n",
        "# rfc.fit(X_train,y_train)\n",
        "\n",
        "# #Calc Probability\n",
        "# rfc_probs = rfc.predict_proba(X_test)\n",
        "# rfc_score = log_loss(y_test,rfc_probs)\n",
        "\n",
        "# # Probability Calibration (sigmoid method)\n",
        "# sig_rfc = CalibratedClassifierCV(rfc, method=\"sigmoid\", cv=\"prefit\")\n",
        "# sig_rfc.fit(X_train, y_train)\n",
        "# sig_rfc_probs = sig_rfc.predict_proba(X_test)\n",
        "# sig_rfc_score = log_loss(y_test, sig_rfc_probs)\n",
        "\n",
        "# # Probability Calibration (sigmoid method)\n",
        "# iso_rfc = CalibratedClassifierCV(rfc, method=\"isotonic\", cv=\"prefit\")\n",
        "# iso_rfc.fit(X_train, y_train)\n",
        "# iso_rfc_probs = iso_rfc.predict_proba(X_test)\n",
        "# iso_rfc_score = log_loss(y_test, iso_rfc_probs)\n",
        "\n",
        "\n",
        "# print(\"RFC Log Loss (no calibration) : %1.3f\" % rfc_score)\n",
        "# print(\"RFC Log Loss (sigmoid) : %1.3f\" % sig_rfc_score)\n",
        "# print(\"RFC Log Loss (isotonic) : %1.3f\" % iso_rfc_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SghFtGH0V1q3"
      },
      "outputs": [],
      "source": [
        "models['RandomForest'].fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg-pmT_NV1q3"
      },
      "outputs": [],
      "source": [
        "categorical_list = X.select_dtypes(exclude = ['float','int']).columns.to_list()\n",
        "ds = Dataset(pd.concat([X_test, y_test], axis=1),cat_features=categorical_list,\n",
        "            features=X.columns,\n",
        "            label='income')\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def calibration_score(testset, model):\n",
        "    \"\"\"\n",
        "    Function:\n",
        "    Calculate the calibration curve with brier score for each class\n",
        "    \n",
        "    Argument:\n",
        "    testset: deepcheck wrapped test data\n",
        "    model: trained model\n",
        "    \"\"\"\n",
        "    try:\n",
        "        check = CalibrationScore()\n",
        "        result = check.run(testset, model)\n",
        "        return result.display[-2]\n",
        "    except:\n",
        "        print(bold,Fore.RED +\"function calibration score failed\")\n",
        "\n",
        "calibration_score(ds,models['RandomForest'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chvN-KhRV1q3"
      },
      "source": [
        "- ft == Predicted probablistic score \n",
        "- ot == What is your actual prediction(test data point)\n",
        "- N == No. of Datapoints which needs to be predicted[future prediction instances]\n",
        "- BS == Lower the score (Near to \"0\") will be considered best Brier score , given the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2QLJQOQV1q3"
      },
      "outputs": [],
      "source": [
        "train_frac = 0.33\n",
        "test_frac = 0.33\n",
        "\n",
        "train_X = df1[[c for c in df1.columns if c != 'income']].iloc[:int(len(df1) * train_frac)].values\n",
        "train_y = df1.income.iloc[:int(len(df1) * train_frac)].values\n",
        "\n",
        "test_X = df1[[c for c in df1.columns if c != 'income']].iloc[int(len(df1) * train_frac):int(len(df1) * (train_frac+test_frac))].values\n",
        "test_y = df1.income.iloc[int(len(df1) * train_frac):int(len(df1) * (train_frac+test_frac))].values\n",
        "\n",
        "valid_X = df1[[c for c in df1.columns if c != 'income']].iloc[int(len(df1) * (train_frac+test_frac)):].values\n",
        "valid_y = df1.income.iloc[int(len(df1) * (train_frac+test_frac)):].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iOWQOoFV1q3"
      },
      "outputs": [],
      "source": [
        "print(\"Train_dataset---->\",train_X.shape)\n",
        "print(\"Train_dataset---->\",test_X.shape)\n",
        "print(\"Train_dataset---->\",valid_X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsqaMdqIV1q3"
      },
      "outputs": [],
      "source": [
        "model_to_clf = {\n",
        "    'rf': RandomForestClassifier,\n",
        "    'svc': SVC,\n",
        "    'nb': GaussianNB\n",
        "    # 'adb': AdaBoostClassifier\n",
        "               }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMoZycyRV1q3"
      },
      "outputs": [],
      "source": [
        "model_to_probs = {}\n",
        "model_str_to_trained_model = {}\n",
        "\n",
        "for model_str, model in model_to_clf.items():\n",
        "    print(model)\n",
        "    if model == SVC:\n",
        "        clf = model(probability=True)\n",
        "    elif model == LogisticRegression:\n",
        "        clf = model(solver='liblinear')\n",
        "    else:\n",
        "        clf = model()\n",
        "        \n",
        "    clf.fit(train_X, train_y)\n",
        "    \n",
        "    pred_probs_train = clf.predict_proba(train_X)[:,1]\n",
        "    pred_probs_test = clf.predict_proba(test_X)[:,1]\n",
        "    pred_probs_valid = clf.predict_proba(valid_X)[:,1]\n",
        "    \n",
        "    model_to_probs[model_str] = {'train': pred_probs_train, 'test': pred_probs_test, 'valid': pred_probs_valid}\n",
        "    \n",
        "    plt.figure(figsize=(10,4))\n",
        "    \n",
        "    plt.subplot(1,2,1)\n",
        "    sns.distplot(pred_probs_train)\n",
        "    plt.title(f\"{model_str} - train\", fontsize=20)\n",
        "    \n",
        "    plt.subplot(1,2,2)\n",
        "    sns.distplot(pred_probs_test)\n",
        "    plt.title(f\"{model_str} - test\", fontsize=20)\n",
        "    \n",
        "    model_str_to_trained_model[model_str] = clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gn0MOMnHV1q3"
      },
      "outputs": [],
      "source": [
        "for model_str, pred_prob_dict in model_to_probs.items():\n",
        "    pred_probs = pred_prob_dict['test']\n",
        "\n",
        "    pred_probs_space = np.linspace(pred_probs.min(), pred_probs.max(), 10)\n",
        "\n",
        "    empirical_probs = []\n",
        "    pred_probs_midpoints = []\n",
        "\n",
        "    for i in range(len(pred_probs_space)-1):\n",
        "        empirical_probs.append(np.mean(test_y[(pred_probs > pred_probs_space[i]) & (pred_probs < pred_probs_space[i+1])]))\n",
        "        pred_probs_midpoints.append((pred_probs_space[i] + pred_probs_space[i+1])/2)\n",
        "\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.plot(pred_probs_midpoints, empirical_probs, linewidth=2, marker='o')\n",
        "    plt.title(f\"{model_str}\", fontsize=20)\n",
        "    plt.xlabel('predicted prob', fontsize=14)\n",
        "    plt.ylabel('Fraction of positives', fontsize=14)\n",
        "    \n",
        "    plt.plot([0,1],[0,1],linestyle='--',color='gray')\n",
        "    \n",
        "    plt.legend(['original', 'ideal'], fontsize=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eK51enTDV1q3"
      },
      "outputs": [],
      "source": [
        "model_str_to_calibrator = {}\n",
        "\n",
        "for model_str, pred_prob_dict in model_to_probs.items():\n",
        "    #train calibration model\n",
        "    lr_model = LogisticRegression()\n",
        "    lr_model.fit(pred_prob_dict['test'].reshape(-1,1), test_y)\n",
        "    \n",
        "    pred_probs = pred_prob_dict['valid']\n",
        "\n",
        "    pred_probs_space = np.linspace(pred_probs.min(), pred_probs.max(), 10)\n",
        "\n",
        "    empirical_probs = []\n",
        "    pred_probs_midpoints = []\n",
        "\n",
        "    for i in range(len(pred_probs_space)-1):\n",
        "        empirical_probs.append(np.mean(valid_y[(pred_probs > pred_probs_space[i]) & (pred_probs < pred_probs_space[i+1])]))\n",
        "        pred_probs_midpoints.append((pred_probs_space[i] + pred_probs_space[i+1])/2)\n",
        "\n",
        "    calibrated_probs = lr_model.predict_proba(np.array([0.0]+pred_probs_midpoints+[1.0]).reshape(-1,1))[:,1]\n",
        "    \n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.plot(pred_probs_midpoints, empirical_probs, linewidth=2, marker='o')\n",
        "    plt.title(f\"{model_str}\", fontsize=20)\n",
        "    plt.xlabel('predicted prob', fontsize=14)\n",
        "    plt.ylabel('Fraction of positives', fontsize=14)\n",
        "    \n",
        "    plt.plot([0.0]+pred_probs_midpoints+[1.0], calibrated_probs, linewidth=2, marker='o')\n",
        "    \n",
        "    plt.plot([0,1],[0,1],linestyle='--',color='gray')\n",
        "    \n",
        "    plt.legend(['original', 'calibrated', 'ideal'], fontsize=20)\n",
        "    \n",
        "    model_str_to_calibrator[model_str] = lr_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgyw_KLqV1q3"
      },
      "outputs": [],
      "source": [
        "clf = model_str_to_trained_model['rf']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PzRS3fxV1q4"
      },
      "outputs": [],
      "source": [
        "lr = model_str_to_calibrator['rf']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4qnbgI5V1q4"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random_value = []\n",
        "for i in range(107):\n",
        "    random_value.append(random.random())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tcf1EENiV1q4"
      },
      "outputs": [],
      "source": [
        "new_sample = np.array([random_value])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gK2VpVMV1q4"
      },
      "outputs": [],
      "source": [
        "uncal_prob = clf.predict_proba(new_sample)[:,1][0]\n",
        "print('Uncalibrated Prob:', uncal_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJNWaWtjV1q4"
      },
      "outputs": [],
      "source": [
        "cal_prob = lr.predict_proba(np.array([[uncal_prob]]))[:,1][0]\n",
        "print('Calibrated Prob:', cal_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ei7eb-tuV1q4"
      },
      "outputs": [],
      "source": [
        "#train and test frames\n",
        "#train and test frames\n",
        "df_class = df1.copy()\n",
        "target_class = 'income'\n",
        "y= df_class[target_class]\n",
        "X= df_class[df_class.columns.difference([target_class])]\n",
        "\n",
        "\n",
        "\n",
        "##Train Test split\n",
        "train_df_class, test_df_class = train_test_split(df_class, test_size=0.33, random_state=42)\n",
        "print(train_df_class.shape)\n",
        "print(test_df_class.shape)\n",
        "\n",
        "\n",
        "trainset_class = Dataset(train_df_class, label=target_class, cat_features=categorical_list)\n",
        "testset_class = Dataset(test_df_class, label=target_class, cat_features=categorical_list)#HERE TARGET IS CATEGORICAL VARIABLE \"SPECIES\"\n",
        "\n",
        "\n",
        "\n",
        "## Model fit\n",
        "clf = RandomForestClassifier(random_state=0, n_estimators=100)\n",
        "model_class = clf.fit(trainset_class.data[trainset_class.features], trainset_class.data[trainset_class.label_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAq9YAVyPYzt"
      },
      "outputs": [],
      "source": [
        "def model_inference_time(testset,model):\n",
        "    '''\n",
        "    Function:\n",
        "    Check for the inference time of the model\n",
        "    \n",
        "    Parameter:\n",
        "    dataset :Deepchecks wrapped dataframe\n",
        "    '''\n",
        "    try:\n",
        "        check = ModelInferenceTime()\n",
        "        result = check.run(testset, model)\n",
        "        return result.display[-1]\n",
        "    except Exception as e:\n",
        "        print(bold,Fore.RED +\"Model inference failed\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAYoalc4PYoF"
      },
      "outputs": [],
      "source": [
        "model_inference_time(testset_class,model_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hM72NIxV1q4"
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.checks import ModelInferenceTime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5vAz1g5PYcK"
      },
      "outputs": [],
      "source": [
        "check = ModelInferenceTime(n_samples = 60)\n",
        "result = check.run(testset_class,model_class)\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9U9tmYDPYZN"
      },
      "outputs": [],
      "source": [
        "from deepchecks.checks import TrainTestLabelDrift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ch5YPbtYPYWJ"
      },
      "outputs": [],
      "source": [
        "def train_test_label_drift(trainset, testset,max_num_categories):\n",
        "    \"\"\"\n",
        "    Calculate label drift between train dataset and test dataset\n",
        "    \n",
        "    Parameter:\n",
        "    trainset: train data set\n",
        "    testset: test data set \n",
        "    max_num_categories:int: Max number of allowed categories\n",
        "    \"\"\"\n",
        "    try:\n",
        "        check = TrainTestLabelDrift(max_num_categories)\n",
        "        result = check.run(trainset, testset)\n",
        "        return result.display[-1]\n",
        "    except:\n",
        "        print(\"function train test label drift failed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do-C9yRqPYTP"
      },
      "outputs": [],
      "source": [
        "train_test_label_drift(trainset_class, testset_class,max_num_categories = None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PWq67c_YdlIb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}